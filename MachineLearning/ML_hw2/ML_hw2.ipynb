{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística: Predicción de Enfermedad Coronaria\n",
    "\n",
    "A continuación se observa un problema de clasificación binaria y se desea analizar una posible solución a partir de un modelo de regresión logística. Se busca implementar el algoritmo mencionado, inicialmente empleando la librería SciKit-Learn para luego desarrollar el mismo proceso de entrenamiento manualmente (Descenso de Gradiente Estocástico).\n",
    "\n",
    "También se introducirán algunos conceptos para lidiar con datos desbalanceados como: matriz de confusión, curva ROC, y algunas otras métricas importantes.\n",
    "\n",
    "Debe completar las celdas vacías y seguir las instrucciones anotadas en el cuaderno.\n",
    "\n",
    "La fecha límite de entrega es el día **20 de septiembre** y se realizará a través de Bloque Neón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heart_df=pd.read_csv(\"heartDisease/framingham.csv\")\n",
    "heart_df.dropna(axis=0,inplace=True)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Se tienen {len(heart_df)} datos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Distribución de Clases\n",
    "\n",
    "En el diagrama a continuación puede observar un claro desbalanceo de los datos, en pasos posteriores hablaremos al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df['TenYearCHD'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de Variables\n",
    "\n",
    "Cada atributo es un factor potencial de riesgo. Existen factores demográficos, conductuales y médicos.\n",
    "\n",
    "- Demográfico:\n",
    "\n",
    "    - male: masculino (1) o femenino (0); (Nominal)\n",
    "\n",
    "    - age: edad del paciente; (Continuo: aunque las edades registradas se han truncado a números enteros, el concepto de edad es continuo)\n",
    "\n",
    "- Comportacional:\n",
    "\n",
    "    - currentSmoker: si el paciente es o no fumador actual (nominal)\n",
    "\n",
    "    - cigsPerDay: la cantidad de cigarrillos que la persona fumó en promedio en un día (se puede considerar continuo ya que uno puede tener cualquier cantidad de cigarrillos, incluso medio cigarrillo).\n",
    "\n",
    "- Historia médica:\n",
    "\n",
    "    - BPMeds: si el paciente estaba o no tomando medicación para la presión arterial (nominal)\n",
    "\n",
    "    - prevalentStroke: si el paciente había tenido previamente un accidente cerebrovascular o no (nominal)\n",
    "\n",
    "    - prevalentHyp: si el paciente era hipertenso (nominal)\n",
    "\n",
    "    - diabetes: si el paciente tenía diabetes o no (nominal)\n",
    "\n",
    "- Estado Médico actual:\n",
    "\n",
    "    - totChol: nivel de colesterol total (continuo)\n",
    "\n",
    "    - sysBP: presión arterial sistólica (continua)\n",
    "\n",
    "    - diaBP: presión arterial diastólica (continua)\n",
    "\n",
    "    - IMC: índice de masa corporal (continuo)\n",
    "\n",
    "    - heartRate: frecuencia cardíaca (continua: en la investigación médica, variables como la frecuencia cardíaca, aunque de hecho son discretas, se consideran continuas debido a la gran cantidad de valores posibles).\n",
    "\n",
    "    - glucose: nivel de glucosa (continuo)\n",
    "\n",
    "- **Variable a Predecir**\n",
    "\n",
    "    - TenYearCHD: Riesgo de padecer enfermedad coronaria 10 años en el futuro (binario: \"1\", significa \"Sí\", \"0\" significa \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = heart_df.values\n",
    "scaler = # Utilice un MinMaxScaler en esta ocasión #\n",
    "x_scaled = # Aplique el escalamiento #\n",
    "heart_df_scaled = pd.DataFrame(x_scaled, columns=heart_df.columns) # Conversión a un DataFrame #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = heart_df_scaled.iloc[:,:-1]\n",
    "y = heart_df_scaled.iloc[:,-1]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "\n",
    "A continuación, debe utilizar la función `LogisticRegression` de SciKit-Learn para obtener un primer modelo de regresión logística y calcular su precisión a partir de la función `accuracy_score`.\n",
    "\n",
    "Obtenga resultados sobre los datos de entrenamiento y los datos de prueba. Concluya al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = # Modelo de Regresión Logística #\n",
    "logreg. # Entrenamiento sobre los Datos #\n",
    "y_pred = logreg.predict(x_test) # Predicción de Etiquetas #\n",
    "\n",
    "print(f'Precisión inicial: {# INCLUYA AQUÍ EL CÁLCULO DE LA PRECISIÓN DEL MODELO #}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusión\n",
    "\n",
    "Como recordará, la información en este dataset no posee una distribución de clases balanceada. La matriz de confusión es una herramienta que permite analizar el comportamiento del modelo para estos datos.\n",
    "\n",
    "Puede encontrar más información en este artículo: [Understanding Confusion Matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de Datos Desbalanceados\n",
    "\n",
    "En casos de estudio como identificación de tendencias patológicas, es común tener datos desbalanceados, o en los cuales la gravedad de cometer [errores tipo I o tipo II](https://www.simplypsychology.org/type_I_and_type_II_errors.html) son bastante diferentes. En muchos casos, se puede preferir cometer cierto tipo de error sobre el otro. Para trabajar con estos problemas, se suele preferir sacrificar algo de [precisión](https://developers.google.com/machine-learning/crash-course/classification/accuracy) del modelo, a cambio de una mejora en términos prácticos.\n",
    "\n",
    "Este proceso se realiza a partir de la modificación del umbral a partir del cual se decide si un dato pertenece a una clase u otra. Utilice la función `binarize` para obtener valores de `0` ó `1` según las probabilidades de las predicciones realizadas utilizando la función `model.predict_proba`.\n",
    "\n",
    "Algunas métricas utilizadas para interpretar el rendimiento del modelo son las siguientes:\n",
    "\n",
    "- F1Score\n",
    "- TP Rate / Recall / Sensitividad\n",
    "- TN Rate / Especificidad\n",
    "\n",
    "Puede encontrar más información sobre estas métricas en los artículos:\n",
    "- [Accuracy, Precision, Recall or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)\n",
    "- [Sensitivity Vs Specificity In Data Science](https://medium.com/fintechexplained/sensitivity-vs-specificity-in-data-science-2f673039dbd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "umbrales = # Vector que Contiene los Umbrales a Analizar #\n",
    "\n",
    "for umbral in umbrales:\n",
    "    cm2 = 0\n",
    "    y_pred_prob_yes = # Utilice la función predict_proba para calcular las probabilidades de pertenecer a la clase 1 #\n",
    "    y_pred2 = # Utilice la función binarize para convertir las probabilidades a clases 0 y 1 #\n",
    "    cm2 = confusion_matrix(y_test,y_pred2)\n",
    "    print(f'''->Para un umbral de {round(umbral,4)} tenemos esta matriz de confusión:\n",
    "{cm2}\n",
    "Con {cm2[0,0]+cm2[1,1]} predicciones correctas y {cm2[1,0]} falsos positivos.\n",
    "Sensitividad: {round(cm2[1,1]/(float(cm2[1,1]+cm2[1,0])), 4)} Especificidad: {round(cm2[0,0]/(float(cm2[0,0]+cm2[0,1])), 4)}\\n''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, un criterio que facilita el visualizar este trade-off se conoce como la Curva ROC, en donde se ubican múltiples puntos para distintos valores del umbral de clasificación. Puede leer el artículo a continuación para una explicación más detallada:\n",
    "- Curva ROC: [Understanding AUC - ROC Curve](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_yes[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('Curva ROC para Clasificador de Enfermedad Coronaria')\n",
    "plt.xlabel('Tasa de Falsos Positivos (1-Especificidad)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (Sensitividad)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe la gráfica, y teniendo en cuenta los resultados concluya sobre la proporción que se puede considerar más adecuada en este contexto.\n",
    "\n",
    "## Parte 2\n",
    "\n",
    "Ahora usted debe desarrollar su propia implementación del método Descenso de Gradiente estocástico para un modelo de regresión logística. Realice el entrenamiento a partir del 80% de los datos. Al final del entrenamiento, en la lista errores se deben tener los valores de la función de error para cada iteración y así poder observar el progreso gráficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)\n",
    "X_train_array = np.c_[np.ones(x_train.values.shape[0]), x_train.values]\n",
    "y_train_array = y_train.values\n",
    "\n",
    "w0 = np.random.rand(X_train_array.shape[1]) # Inicialización de w #\n",
    "\n",
    "w = w0.copy()\n",
    "# Inicialización de criterio de parada (al disminuir el valor de eps, se aumenta la precisión y el tiempo de procesamiento)\n",
    "eps = 1e-5\n",
    "error = 100\n",
    "dif = 100\n",
    "\n",
    "def sigma(w,x):\n",
    "    res_sigmoid = # Salida de la función sigmoide #\n",
    "    return res_sigmoid\n",
    "\n",
    "tasas = # Defina un vector que contenga las tasas que desea probar #\n",
    "for tasa in tasas:\n",
    "    # while error>eps:         # Criterio de parada 1 #\n",
    "    for j in range (0, 1000):  # Criterio de parada 2 #\n",
    "        # # Desarrollo de algoritmo # #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # # # # # # # # # # # # # # # #\n",
    "    X_test_array = np.c_[np.ones(x_test.values.shape[0]), x_test.values]\n",
    "    y_test_array = y_test.values\n",
    "\n",
    "    y_pred = np.zeros(len(x_test))\n",
    "\n",
    "    for i in range(0,len(x_test)):\n",
    "      prob = sigma(w,X_test_array[i])\n",
    "      if prob>0.5:\n",
    "        y_pred[i] = 1\n",
    "      else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "    print(f'Precisión modelo actual: {sklearn.metrics.accuracy_score(y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusión\n",
    "\n",
    "Observe y analice la matriz de confusión para su mejor modelo. Escriba claramente sus conclusiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "sn.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
